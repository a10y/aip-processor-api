/*
 * (c) Copyright 2019 Palantir Technologies Inc. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

import "google/protobuf/duration.proto";

option java_package = "com.palantir.aip.proto.processor.v1";
option java_outer_classname = "ProcessorV1Protos";

/*
 * The Orchestrator supports clients that either implement the gRPC service defined as ProcessingService below or
 * a local TCP based protocol that operates as follows:
 *
 * 1. Orchestrator connects to the ModelServer over a local TCP socket.
 * 2. Orchestrator sends an `ConfigurationRequest` message.
 * 3. ModelServer responds with a `ConfigurationResponse` message.
 * 4. Orchestrator begins to send `Frame` messages.
 * 5. ModelServer responds with `Result` message whenever available.
 *
 * Orchestrator will use Results from the ModelServer if they arrive before the
 * indicated deadline.
 *
 * ModelServer can choose to ignore/skip any Frames.
 *
 * All messages sent over the socket must be prefixed by a big-endian
 * 4 byte length of the serialized message.
 */
package aip;

service ProcessingService {
    rpc Process (Request) returns (Response) {}
}

message ProcessorV1Config {
    /** Indicates to the orchestrator what type of Frames to emit to this provider. */
    FrameType frame_type = 1;
}

message Request {
    oneof request {
        /** Request for a provider to return information about its setup. */
        ConfigurationRequest configuration = 1;

        /** Request to process a single Frame. */
        Frame frame = 2;
    }
}

message Response {
    oneof response {
        ConfigurationResponse configuration = 1;
        Result result = 2;
    }
}

message ConfigurationRequest {
    /** Human readable name of the orchestrator. */
    string orchestrator_name = 1;

    /** Human readable version of the orchestrator. */
    string orchestrator_version = 2;
}

message ConfigurationResponse {
    /** Human readable name of the provider. */
    string provider_name = 1;

    /** Human readable version of the provider. */
    string provider_version = 2;

    /** Indicates to the orchestrator what type of Frames to emit to this provider. */
    FrameType frame_type = 3;
}

enum FrameType {
    RGB888 = 0;
    PNG = 1;
    TIFF = 2;
    BGR888 = 3;
}

/** The unique identifier for a `Frame` and its associated `Result`. */
message Identifier {
    uint64 stream_id = 1;
    uint64 frame_id = 2;
}

message Result {
    Identifier identifier = 1;

    oneof result {
        GeoRegistration geo_registration = 2;
        Inferences inferences = 3;
    }
}

message GeoRegistration {
    Lattice lattice = 1;
    double confidence = 2;
    UasMetadata updatedMetadata = 3;
}

message Inferences {
    repeated Inference inference = 1;
}

message Inference {
    /** Persistent id of a particular inference that's used to tie together inferences across frames. */
    string inferenceId = 1;

    oneof inference {
        BoundingBox box = 2;
        BoundingPolygon polygon = 3;
    }
}

/*
 * A rectangular container defined by its coordinates:
 *   drawn from (c0.row, c0.col) to (c1.row, c1.col)
 *   height = c1.row - c0.row
 *   width = c1.col - c0.col
 */
message BoundingBox {
    /** Upper left corner */
    UnitCoordinate c0 = 1;

    /** Lower right corner */
    UnitCoordinate c1 = 2;

    /**
     * Each BoundingBox may be labeled with potentially many classifications. Classifications do not necessarily need
     * to relate, and itâ€™s valid, for instance, to return results such as:
     *   [ motorcycle: 0.5, person: 0.5]
     *   [ vehicle: 0.9, car: 0.5, truck: 0.4 ]
     */
    repeated Classification classifications = 3;
}

message BoundingPolygon {
    Polygon polygon = 1;
    repeated Classification classifications = 2;
}

/** A closed polygon defined by the provided vertices (last vertex is connected to the first). */
message Polygon {
    repeated UnitCoordinate vertices = 1;
}

/**
 * Specifies a location where row and col are specified in unit space [0,1].
 * Corners have the following UnitCoordinates:
 *
 * Upper-Left   row: 0  col: 0
 * Upper-Right  row: 0  col: 1
 * Lower-Left   row: 1  col: 0
 * Lower-Right  row: 1  col: 1
 */
message UnitCoordinate {
    double row = 1;
    double col = 2;
}

message Classification {
    /** A pre-agreed identifier that the orchestration system is agnostic to. */
    string type = 1;

    /** Value in the range [0,1] representing how likely the referenced object is the given type. */
    double confidence = 2;
}

/** Square lattice of points representing the intersection of the sensor with the Earth. */
message Lattice {
    message Point {
        /** Coordinate in the image that corresponds to the given lat, long, and elevation. */
        UnitCoordinate coordinate = 1;

        /** Degrees. Latitude. */
        double latitude = 2;

        /** Degrees. Longitude. */
        double longitude = 3;

        /** Meters. Elevation. */
        double elevation = 4;
    }

    repeated Point earth_intersection = 1;
}

message Frame {
    Identifier identifier = 1;
    google.protobuf.Duration deadline = 2;

    Image image = 3;
    UasMetadata uasMetadata = 4;
}

message Image {
    oneof image {
        Rgb888Image rgb_image = 1;
        PngImage png_image = 2;
        TiffImage tiff_image = 3;
        Bgr888Image bgr_image = 4;
    }
}

message Rgb888Image {
    int32 width = 1;
    int32 height = 2;

    /*
     * An RGB888 image arranged in hwc (height-width-channel) order.
     *
     * In order to get the pixel value at row 'r' and column 'c', you would index into the file as follows:
     *
     * ```
     * int rowOffset    = r * width * 3
     * int columnOffset = c * 3
     * int pixelIndex   = rowOffset + columnOffset
     * byte red   = bytes[pixelIndex]
     * byte green = bytes[pixelIndex + 1]
     * byte blue  = bytes[pixelIndex + 2]
     * ```
     */
    string path = 3;
}

message Bgr888Image {
    int32 width = 1;
    int32 height = 2;

    /** An BGR888 image arranged in hwc (height-width-channel) order. */
    string path = 3;
}

message PngImage {
    int32 width = 1;
    int32 height = 2;

    /*
     * The path to a PNG encoded image.
     */
    string path = 3;
}

message TiffImage {
    int32 width = 1;
    int32 height = 2;

    /*
     * The path to a TIFF encoded image.
     */
    string path = 3;
}

/*
 * Subset of the tags from 0601.4, with tag number == protobuf field number.
 */
message UasMetadata {
    /** Degrees within range [0, 360]. Aircraft heading angle. Relative between longitudinal axis and True North measured in the horizontal plane. */
    float platform_heading_angle = 5;

    /** Degrees within range [-20, 20]. Aircraft pitch angle. Angle between longitudinal axis and horzontal plane. Positive angles above horizontal plane. */
    float platform_pitch_angle = 6;

    /** Degrees within range [-50, 50]. Platform roll angle. Angle between transverse axis and horizontal plane. Positive angles for right wing lowered below horizontal plane. */
    float platform_roll_angle = 7;

    /** Degrees within range [-90, 90]. Sensor Latitude. Based on WGS84 ellipsoid. */
    double sensor_latitude = 13;

    /** Degrees within range [-180, 180]. Sensor Longitude. Based on WGS84 ellipsoid. */
    double sensor_longitude = 14;

    /** Meters within range [-900, 19000]. Altitude of sensor as measured from Mean Sea Level (MSL). */
    double sensor_true_altitude = 15;

    /** Degrees within range [0, 180]. Horizontal field of view of selected imaging sensor. */
    float sensor_horizontal_fov = 16;

    /** Degrees within range [0, 180]. Vertical field of view of selected imaging sensor. */
    float sensor_vertical_fov = 17;

    /** Degrees within range [0, 360]. Relative rotation angle of sensor to platform longitudinal axis. Rotation angle between platform longitudinal axis and camera pointing direction as seen from above the platform. */
    double sensor_relative_azimuth_angle = 18;

    /** Degrees within range [-180, 180]. Relative Elevation Angle of sensor to platform longitudinal-transverse plane. Negative angles down. */
    double sensor_relative_elevation_angle = 19;

    /** Degrees within range [0, 360]. Relative roll angle of sensor to aircraft platform. Twisting angle of camera about lens axis. Top of image is zero degrees. Positive angles are clockwise when looking from behind camera. */
    double sensor_relative_roll_angle = 20;
}
